{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.115.6)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.34.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.42.3)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.9.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.23.4)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi) (0.41.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi) (4.11.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from starlette<0.42.0,>=0.40.0->fastapi) (4.6.2.post1)\n",
      "Requirement already satisfied: sympy in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mechg\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install fastapi uvicorn transformers sentence-transformers scikit-learn pydantic huggingface_hub pyngrok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from pyngrok import ngrok\n",
    "login(token=\"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\")\n",
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(\"2im79GDDlYxzJuiSPExFduCvTlP_3rHxmhf6g5e1F9pmgBzYb\")\n",
    "\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "class Query(BaseModel):\n",
    "    query: str\n",
    "\n",
    "class SocialMediaRAG:\n",
    "    def __init__(self, trends_df: pd.DataFrame, songs_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize the RAG system with DataFrame inputs instead of CSV paths.\n",
    "\n",
    "        Args:\n",
    "            trends_df: DataFrame containing trends data\n",
    "            songs_df: DataFrame containing songs data\n",
    "        \"\"\"\n",
    "        print(\"Initializing models...\")\n",
    "        # Initialize FLAN-T5 model and tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"google/gemma-2-2b\",\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        # Initialize sentence transformer\n",
    "        print(\"Loading sentence transformer...\")\n",
    "        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "        # Store DataFrames\n",
    "        self.trends_df = trends_df\n",
    "        self.songs_df = songs_df\n",
    "\n",
    "        # Create embeddings\n",
    "        print(\"Creating embeddings...\")\n",
    "        self._create_embeddings()\n",
    "        print(\"Initialization complete!\")\n",
    "\n",
    "    def _create_embeddings(self):\n",
    "        \"\"\"Create and store embeddings for all content\"\"\"\n",
    "        # Process trends\n",
    "        self.trends_texts = []\n",
    "        for _, row in self.trends_df.iterrows():\n",
    "            trend_name = row['Trend Name'].split('|')[0].strip() if pd.notna(row['Trend Name']) else \"\"\n",
    "            explanation = row['Explanation'] if pd.notna(row['Explanation']) else \"\"\n",
    "            trend_text = f\"Trend: {trend_name} | {explanation}\"\n",
    "            self.trends_texts.append(trend_text)\n",
    "\n",
    "        # Process songs\n",
    "        self.songs_texts = []\n",
    "        for _, row in self.songs_df.iterrows():\n",
    "            song_name = row['song_name'] if pd.notna(row['song_name']) else \"\"\n",
    "            artist = row['artist_name'] if pd.notna(row['artist_name']) else \"\"\n",
    "            reels_count = row['reels_count'] if pd.notna(row['reels_count']) else \"0\"\n",
    "            description = row['description'] if pd.notna(row['description']) else \"\"\n",
    "            \n",
    "            song_text = f\"Song: {song_name} by {artist} | Reels: {reels_count} | {description}\"\n",
    "            self.songs_texts.append(song_text)\n",
    "\n",
    "        # Combine all texts\n",
    "        self.all_texts = self.trends_texts + self.songs_texts\n",
    "\n",
    "        # Create embeddings\n",
    "        self.content_embeddings = self.encoder.encode(self.all_texts, convert_to_tensor=True)\n",
    "\n",
    "    def _get_relevant_content(self, query: str, top_k: int = 3) -> dict:\n",
    "        \"\"\"Get relevant content based on query\"\"\"\n",
    "        query_embedding = self.encoder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        similarities = cosine_similarity(\n",
    "            query_embedding.cpu().numpy().reshape(1, -1),\n",
    "            self.content_embeddings.cpu().numpy()\n",
    "        )[0]\n",
    "\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        relevant_content = [self.all_texts[i] for i in top_indices]\n",
    "\n",
    "        return {\n",
    "            'relevant_content': relevant_content,\n",
    "            'similarity_scores': similarities[top_indices]\n",
    "        }\n",
    "\n",
    "    def generate_response(self, query: str) -> str:\n",
    "        \"\"\"Generate response to query with a single cohesive answer\"\"\"\n",
    "        try:\n",
    "            # Get relevant content\n",
    "            content = self._get_relevant_content(query)\n",
    "\n",
    "            # Create prompt with a clear instruction to generate one response\n",
    "            context_str = \"\\n\".join([\n",
    "                f\"[Relevance: {score:.2f}] {text}\"\n",
    "                for text, score in zip(content['relevant_content'], content['similarity_scores'])\n",
    "            ])\n",
    "\n",
    "            prompt = f\"\"\"Based on the following social media trends and songs:\n",
    "\n",
    "    {context_str}\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    Provide a single, cohesive, and creative response, combining insights from the trends and songs to suggest how to promote face products in an engaging way. If the question is out of context of RAG I want you to give a generative answer with latest relevance.\"\"\"\n",
    "\n",
    "            # Generate response\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "            inputs = inputs.to(self.model.device)\n",
    "            \n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_length=300,\n",
    "                min_length=100,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=1\n",
    "            )\n",
    "\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            return response.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "\n",
    "# Load and preprocess the CSV files for initializing the model\n",
    "# Replace with your own CSV loading code\n",
    "latest_trends = pd.read_csv(\"latest_insta_trends.csv\")\n",
    "archived_trends = pd.read_csv(\"archived_insta_trends.csv\")\n",
    "songs_df = pd.read_csv(\"instagram_trending_songs.csv\")\n",
    "\n",
    "# Combine trends (latest and archived)\n",
    "combined_trends_df = pd.concat([latest_trends, archived_trends], ignore_index=True)\n",
    "\n",
    "# Initialize the SocialMediaRAG model\n",
    "rag_system = SocialMediaRAG(combined_trends_df, songs_df)\n",
    "\n",
    "@app.post(\"/generate_response/\")\n",
    "async def generate_response(query: Query):\n",
    "    \"\"\"Endpoint to generate response for the query\"\"\"\n",
    "    response = rag_system.generate_response(query.query)\n",
    "    return {\"response\": response}\n",
    "\n",
    "# Set up ngrok to expose the API\n",
    "# Start the server\n",
    "from threading import Thread\n",
    "import uvicorn\n",
    "\n",
    "def start_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "# Start ngrok\n",
    "ngrok.set_auth_token(\"2im79GDDlYxzJuiSPExFduCvTlP_3rHxmhf6g5e1F9pmgBzYb\")\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print(f\"Public URL: {ngrok_tunnel.public_url}\")\n",
    "\n",
    "# Start the FastAPI server in a separate thread\n",
    "server_thread = Thread(target=start_server)\n",
    "server_thread.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
